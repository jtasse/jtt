<!doctype html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Book Review: Empire of AI by Karen Hao - James.Tasse</title>
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link
			href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,200..1000;1,200..1000&family=Helvetica:wght@400..900&display=swap"
			rel="stylesheet"
		/>
		<link rel="stylesheet" href="/src/content/blog/blog.css" />
		<script src="/src/content/blog/blog.js" defer></script>
		<script type="module" src="/src/main.js"></script>
	</head>
	<body>
		<div id="content" class="container">
			<main class="blog-content single-post">
				<article>
					<div class="post-image">
						<img
							src="/src/content/blog/nav-images/empire_of_ai_karen_hao_thumbnail.webp"
							alt="Empire of AI book cover"
						/>
					</div>

					<h1>Book Review: Empire of AI by Karen Hao</h1>
					<div class="post-meta">
						<time datetime="2025-09-04">September 4, 2025</time> | James Tasse |
						4 min read
					</div>

					<h2>The Target</h2>

					<p>
						In her nonfiction book
						<em>Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI</em>,
						Karen Hao seeks to draw parallels between Old World empires like
						those of the British, French, &amp; Spanish and the company OpenAI
						while also examining how the company's CEO Sam Altman has drawn from
						imperialist traditions.
					</p>

					<figure class="post-figure book-cover">
						<img
							src="/src/content/blog/posts/post-images/book-review-empire-of-ai-by-karen-hao/empire-of-ai-book-cover.jpg"
							alt="Empire of AI book cover"
						/>
					</figure>

					<p>
						She begins with a dizzying sequence describing the temporary ouster
						of Sam Altman from OpenAI in 2023 going back and tracing the
						company's chaotic rise. But for every supposed success of OpenAI,
						Hao points to the associated human and environmental costs. For
						example, she describes how "data annotation" workers in Kenya helped
						to filter out "violence and hate speech" from OpenAI models for
						"starvation wages". She also details the significant power needs of
						OpenAI data centers, at one point mentioning a planned data center
						campus that would require (as reported by <em>The Information</em>)
						"5,000 megawatts, nearly matching the average power demands of all
						of New York City."
					</p>

					<p>
						So I would say Ms. Hao makes her case about OpenAI acting like an
						empire (and Sam Altman acting like an emperor) pretty well. But she
						actually goes beyond this, exposing the suspect behaviors of
						Microsoft (Open AI's partner/frenemy), Google, Anthropic (who were
						supposedly the good guys until they weren't), Meta, and even
						X/Tesla/pick-your-favorite-Musk-venture.
					</p>

					<p>
						Hao is so relentless in describing the misbehavior of our beloved
						tech giants—yes even Google, who she points out twice tried to build
						water-hungry data centers in South American countries with severe
						drought—that I actually misremembered the name of the book as
						<em>Empire<strong>s</strong> of AI</em> (plural) and had to
						double-check it before writing this review.
					</p>

					<h2>Core Values</h2>

					<p>
						In a book full of great quotes, the author introduces arguably its
						most salient of them on page 3:
					</p>

					<blockquote>
						<p>
							"...the most successful founders do not set out to create
							companies. They are on a mission to create something closer to a
							religion, and at some point it turns out that forming a company is
							the easiest way to do so."
						</p>
						<cite>—Sam Altman, 2013</cite>
					</blockquote>

					<p>
						This quote immediately resonated with me, as I once worked for a
						company—I won't name it, but I'm sure it wouldn't be hard to figure
						out which one—that attracted me and hundreds (thousands?) of others
						on the strength of its <s>religion</s> culture. The company
						celebrated its core values constantly, and even awarded an "employee
						of the week" for the employee that best embodied one of the values
						for the given week. Even earlier in the company's history, I was
						told of a crisis where employees remained so devoted to the
						company's vision that they temporarily forewent their salaries while
						the company weathered a challenging cashflow situation.
					</p>

					<p>
						So what happened to that company? Well, the problem was that they
						had record profits. *cough*, sorry. The problem was that they had
						record profits
						<em>and some overeager executives/private investors</em>, and this
						led them to make the "tough decision" to lay off dozens of people
						for the first time in the company's history. I left the company
						shortly after the layoffs.
					</p>

					<h2>Not so Nonprofit</h2>

					<p>
						In <em>Empire of AI</em>, Karen Hao recounts the earliest days of
						OpenAI, back when it was actually structured as a true nonprofit
						(<em>technically</em> OpenAI still has a nonprofit component, but as
						the book describes it the nonprofit arm of OpenAI is little more
						than decorative these days). She talks about how the founders,
						including Ilya Sutskever, Elon Musk, and Sam Altman truly believed
						in the idea of creating AGI (Artificial General Intelligence, or an
						AI system that can perform just about any task as well as a human)
						and leveraging it to benefit all of humanity. Someday, they
						believed, AGI could "solve climate change", "cure diseases", and
						usher in an era where everyone has access to UBI (universal basic
						income).
					</p>

					<p>
						But here we are in 2025—ten years after OpenAI was founded and
						despite hundreds of billions of dollars invested—and what does
						OpenAI have to show for their efforts?
					</p>

					<ul>
						<li>No AGI</li>
						<li>
							So many data centers that are <em>accelerating</em> climate change
							and, oh yeah, making our electric bills go up
						</li>
						<li>0 diseases cured</li>
						<li>No UBI</li>
						<li>ChatGPT is kind of neat?</li>
					</ul>

					<h2>The Untainted Vision Economy</h2>

					<p>
						There is a part of me that wants OpenAI to succeed, to give them a
						chance to make good on their original promise of spreading around a
						little prosperity to everyone. But I'm not holding my breath.
					</p>

					<p>
						In <em>Empire of AI</em>, Karen Hao paints the "Safety"
						researchers—I'm thinking of "existential safety" in the sense of
						"trying to make sure AGI or superintelligence doesn't kill us all—as
						the good guys. The prime example would be Dario Amodei, who, along
						with a number of like-minded folks, left OpenAI to found Anthropic
						amid concerns that OpenAI no longer truly cared about safety.
						However, Hao points out that over time Anthropic's view of safety
						has become harder to distinguish from OpenAI's.
					</p>

					<p>This brings to mind a quote:</p>

					<blockquote>
						<p>
							"All of this has happened before, and it will all happen again."
						</p>
						<cite
							>—initially I recalled this from Battlestar Galactica (2004), but
							apparently it originated with J.M. Barrie's Peter Pan (1954)</cite
						>
					</blockquote>

					<p>
						We can't count on bold visions like the one that began with OpenAI
						to magically come to fruition of their own accord. In so many cases
						like that once-unicorn of a company where I worked, like with
						Google, and Microsoft, and well, America; the present reality has
						drifted far afield from the founding ideology. Both from internal
						pressures to succeed against the "other", and external ones to grow
						and innovate at 10x the speed of the competition; entropy seems to
						push our psychological and economic systems in the wrong direction,
						practically by default.
					</p>

					<p>
						But if we follow Karen Hao's lead. If we call out the tech fiends on
						their bullshit. If we stop letting the Sam Altmans wriggle out of
						yet another ridiculous lie/prediction. If we stop the construction
						of another data center that will take our power, our water, and
						accelerate climate change. If we champion the usage of smaller, more
						lightweight AI models and use them instead of the gigantic language
						models like those powering ChatGPT.
					</p>

					<p>
						Then we just might be able to choose our own future (instead of AGI
						choosing it for us).
					</p>

					<h2>Attributions</h2>

					<ul class="attributions">
						<li>
							My copy of the book:
							<a
								href="https://play.google.com/store/books/details/Empire_of_AI_Dreams_and_Nightmares_in_Sam_Altman_s?id=r6M4EQAAQBAJ&amp;hl=en_US"
								>Google Play</a
							>
						</li>
						<li>
							Featured image/thumbnail:
							<a
								href="https://helios-i.mashable.com/imagery/articles/04yKMcFP7f9KJhiI7uJHfll/hero-image.fill.size_1248x702.v1747420776.jpg"
								>Mashable</a
							>
						</li>
						<li>
							Book cover image:
							<a
								href="https://upload.wikimedia.org/wikipedia/en/3/3f/Empire_of_AI_book_cover.jpg"
								>Wikipedia</a
							>
						</li>
						<li>
							"All this has happened before" quote:
							<a
								href="https://www.thestrangeloop.com/2014/all-of-this-has-happened-before-and-it-will-all-happen-again.html"
								>The Strange Loop</a
							>
						</li>
					</ul>
				</article>
			</main>
		</div>
	</body>
</html>
